{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26e41ae-3800-48ff-8932-0407188957be",
   "metadata": {},
   "source": [
    "### Classification Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6553046-2822-4876-bc12-c45177d94393",
   "metadata": {},
   "source": [
    "This time we will use a dataset of images of three different types of the iris flower. This zip file contains three different directories that specify each image's label. The directories are named the same as the labels:\n",
    "\n",
    "- iris-setosa\n",
    "- iris-versicolour\n",
    "- iris-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3426a5f-92d7-41ac-a52d-3cdb5d8b7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow logging: OFF\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f9b848-91a2-43ee-ad80-ebfeddb65053",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://github.com/jeffheaton/data-mirror/releases\"\n",
    "DOWNLOAD_SOURCE = URL+\"/download/v1/iris-image.zip\"\n",
    "DOWNLOAD_NAME = DOWNLOAD_SOURCE[DOWNLOAD_SOURCE.rfind('/')+1:]\n",
    "\n",
    "COLAB = False\n",
    "\n",
    "if COLAB:\n",
    "  PATH = \"/content\"\n",
    "  EXTRACT_TARGET = os.path.join(PATH,\"iris\")\n",
    "  SOURCE = EXTRACT_TARGET # In this case its the same, no subfolder\n",
    "else:\n",
    "  # I used this locally on my machine, you may need different\n",
    "  PATH = \"/tmp\"\n",
    "  EXTRACT_TARGET = os.path.join(PATH,\"iris\")\n",
    "  SOURCE = EXTRACT_TARGET # In this case its the same, no subfolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8c2482-cdaa-4701-afa2-e9e6189017bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-25 17:26:44--  https://github.com/jeffheaton/data-mirror/releases/download/v1/iris-image.zip\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/408419764/d548babd-36c3-414e-add2-a5d9ab941e6e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231025%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231025T162645Z&X-Amz-Expires=300&X-Amz-Signature=19179fd3c4707759437b0710835096b928b66b4ad70f8ff718f146da796fb4c2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=408419764&response-content-disposition=attachment%3B%20filename%3Diris-image.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-10-25 17:26:45--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/408419764/d548babd-36c3-414e-add2-a5d9ab941e6e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231025%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231025T162645Z&X-Amz-Expires=300&X-Amz-Signature=19179fd3c4707759437b0710835096b928b66b4ad70f8ff718f146da796fb4c2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=408419764&response-content-disposition=attachment%3B%20filename%3Diris-image.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5587253 (5.3M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/iris-image.zip’\n",
      "\n",
      "/tmp/iris-image.zip 100%[===================>]   5.33M  8.07MB/s    in 0.7s    \n",
      "\n",
      "2023-10-25 17:26:46 (8.07 MB/s) - ‘/tmp/iris-image.zip’ saved [5587253/5587253]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O {os.path.join(PATH,DOWNLOAD_NAME)} {DOWNLOAD_SOURCE}\n",
    "!mkdir -p {SOURCE}\n",
    "!mkdir -p {TARGET}\n",
    "!mkdir -p {EXTRACT_TARGET}\n",
    "!unzip -o -d {EXTRACT_TARGET} {os.path.join(PATH, DOWNLOAD_NAME)} >/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75bd024-98ee-4206-b2bf-aa4662767798",
   "metadata": {},
   "source": [
    "We set up the generator, similar to before. This time we use flow_from_directory to get the labels from the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ed7705-5798-440c-9931-6d8649a037fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 421 images belonging to 3 classes.\n",
      "Found 421 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  width_shift_range=[-200,200],\n",
    "  rotation_range=360,\n",
    "\n",
    "  fill_mode='nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "    directory=SOURCE, target_size=(256, 256), \n",
    "    class_mode='categorical', batch_size=32, shuffle=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=SOURCE, target_size=(256, 256), \n",
    "    class_mode='categorical', batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67185e0d-fcf3-43e1-94d9-f2c48900256d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 125, 125, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 60, 60, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1180160   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1279139 (4.88 MB)\n",
      "Trainable params: 1279139 (4.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.0359\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.9188\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8948\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.9014\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8739\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.9079\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.9153\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.8912\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8357\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.9274\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8942\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.9112\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8594\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.9059\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8474\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8697\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8719\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8825\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8938\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8767\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8401\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8496\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8933\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8750\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8625\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8783\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.8814\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8439\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8893\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.9071\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8714\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8306\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8387\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.8395\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8482\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.8908\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.9254\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8828\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8470\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8632\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8127\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.9021\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8583\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8470\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8711\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8515\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8473\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8197\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8871\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f94413c4550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class_count = len(train_generator.class_indices)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image \n",
    "    # 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', \n",
    "        input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 \n",
    "    tf.keras.layers.Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(train_generator, epochs=50, steps_per_epoch=10,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ae14a4-f163-457e-9c64-7eaa068fed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 3s 224ms/step\n",
      "Accuracy: 0.6389548693586699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "validation_generator.reset()\n",
    "pred = model.predict(validation_generator)\n",
    "\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = validation_generator.classes\n",
    "\n",
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Accuracy: {correct}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
